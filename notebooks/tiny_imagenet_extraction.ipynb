{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "tiny-imagenet-extraction.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [
    "0zpkfIgJyfsX",
    "FDrMUpUxym13",
    "o6b2N-AHysUq",
    "thzOt2_6f-9v",
    "zufagcZNfDOT",
    "4lA3_HXqlGKS",
    "EiqlSAR9lMEQ",
    "S5iczFQ8lZMo",
    "EJh1lXQAlb73",
    "jSUa7DpWoF_H",
    "Q4ZV4uZAHkqP",
    "tGi3gxqaH8nq",
    "1JaAW6EmIA2J"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Tiny Imaget Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Execute just in remote environment\n",
    "\n",
    "!wget 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
    "!unzip -qq 'tiny-imagenet-200.zip'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine tuning source code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def change_validation_scaffolding(base_route, definition_file, separator):\n",
    "  validation_data = _load_validation_data(definition_file, separator)\n",
    "  \n",
    "  for row in validation_data.iterrows():\n",
    "    file = row[1][\"file\"]\n",
    "    label = row[1][\"label\"]\n",
    "    \n",
    "    label_folder = os.path.join(base_route, label)\n",
    "    \n",
    "    if not os.path.exists(label_folder):\n",
    "      os.mkdir(label_folder)\n",
    "    \n",
    "    shutil.move(os.path.join(base_route, file), os.path.join(label_folder, file))\n",
    "\n",
    "\n",
    "def _load_validation_data(definition_file, separator):\n",
    "  validation_data = pd.read_csv(\n",
    "    definition_file,\n",
    "    sep=separator,\n",
    "    header=None\n",
    "  )\n",
    "  \n",
    "  validation_data.columns = [\"file\", \"label\", \"0\", \"1\", \"2\", \"3\"]\n",
    "  \n",
    "  return validation_datachange_validation_scaffolding(\"tiny-imagenet-200/val/images\", \"tiny-imagenet-200/val/val_annotations.txt\", '\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "change_validation_scaffolding(\"tiny-imagenet-200/val/images\", \"tiny-imagenet-200/val/val_annotations.txt\", '\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.python.keras.applications.densenet import DenseNet201\n",
    "from keras.applications.densenet import DenseNet121\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "class ImageModel:\n",
    "    def __init__(self, base_route, model_name, model_route = \"model.h5\", \n",
    "                 train_folder=\"train\", validation_folder=\"val\", epochs=10, \n",
    "                 fine_tune: bool = False, fine_tune_epochs = 5):\n",
    "                \n",
    "        self.model = None\n",
    "        self.__base_model = None\n",
    "        self.__train_directory_iterator = None\n",
    "        self.__validation_directory_iterator = None\n",
    "        \n",
    "        self.__width = self.__height = 64\n",
    "        self.__train_route = os.path.join(base_route, train_folder)\n",
    "        self.__validation_route = os.path.join(base_route, validation_folder)\n",
    "        self.__model_name = model_name\n",
    "        self.__model_route = model_route\n",
    "        \n",
    "        self.__fine_tuning = fine_tune\n",
    "        \n",
    "        self.__epochs = epochs\n",
    "        self.__batch_size = 64\n",
    "        self.__fine_tune_epochs = fine_tune_epochs\n",
    "        \n",
    "        self.__early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "        self.__checkpoint = self._get_model_checkpoint()\n",
    "        \n",
    "        self.train_size = 0\n",
    "        self.validation_size = 0\n",
    "        self.train_steps = 0\n",
    "        self.validation_steps = 0\n",
    "        \n",
    "    def build(self):\n",
    "        self.__train_directory_iterator = self._get_directory_iterator(self.__train_route, True)\n",
    "        self.__validation_directory_iterator = self._get_directory_iterator(self.__validation_route)\n",
    "        \n",
    "        self.train_size = self.__train_directory_iterator.samples\n",
    "        self.validation_size = self.__validation_directory_iterator.samples\n",
    "        \n",
    "        self._build_model(self.__train_directory_iterator.num_classes)\n",
    "    \n",
    "    def train(self):       \n",
    "        if self.__fine_tuning:\n",
    "            self._set_fine_tune()\n",
    "        else:\n",
    "            self._set_transfer_learning()\n",
    "        \n",
    "        self.__model.fit_generator(\n",
    "            self.__train_directory_iterator,\n",
    "            steps_per_epoch=self.train_steps,\n",
    "            epochs=self.__fine_tune_epochs,\n",
    "            validation_data=self.__validation_directory_iterator,\n",
    "            validation_steps=self.validation_steps,\n",
    "            callbacks=[self.__checkpoint, self.__early_stop]\n",
    "        )\n",
    "        \n",
    "        self.fit_all(train=self.__train_directory_iterator, val=self.__validation_directory_iterator)\n",
    "        \n",
    "        self.__model.save(self.__model_route)\n",
    "        \n",
    "        metrics = self.__model.evaluate_generator(self.__validation_directory_iterator)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def fit_all(self, train, val):\n",
    "        for layer in self.__model.layers:\n",
    "            layer.trainable = True\n",
    "            \n",
    "        self.__model.compile(optimizer=SGD(lr=0.01, momentum=0.6),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "        \n",
    "        self.__model.fit_generator(\n",
    "            train,\n",
    "            steps_per_epoch=self.train_steps,\n",
    "            epochs=self.__epochs,\n",
    "            validation_data=val,\n",
    "            validation_steps=self.validation_steps,\n",
    "            callbacks=[self.__checkpoint, self.__early_stop]\n",
    "        )\n",
    "    \n",
    "    def _build_model(self, num_classes: int):\n",
    "        \n",
    "        if self.__model_name == \"vgg19\":\n",
    "            self.__base_model = VGG19(weights='imagenet', include_top=False, input_shape=(self.__width, self.__height, 3))\n",
    "        elif self.__model_name == \"resnet\":\n",
    "            self.__base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(self.__width, self.__height, 3))\n",
    "        elif self.__model_name == \"densenet121\":\n",
    "            self.__base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(self.__width, self.__height, 3))\n",
    "        elif self.__model_name == \"DenseNet201\":\n",
    "            self.__base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(self.__width, self.__height, 3))\n",
    "        \n",
    "        x = self.__base_model.output\n",
    "\n",
    "        x = Concatenate()([GlobalAveragePooling2D()(x), GlobalMaxPooling2D()(x)])\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(1024 / 2, activation='relu')(x)\n",
    "        \n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "        predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "        self.__model = Model(inputs=self.__base_model.input, outputs=predictions)\n",
    "    \n",
    "    def _set_transfer_learning(self):\n",
    "        for layer in self.__base_model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        self.__model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def _set_fine_tune(self):\n",
    "        layers_to_freeze = int(len(self.__base_model.layers) * 0.9)\n",
    "        \n",
    "        for layer in self.__model.layers[:layers_to_freeze]:\n",
    "            layer.trainable = False\n",
    "        for layer in self.__model.layers[layers_to_freeze:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        self.__model.compile(\n",
    "            optimizer=SGD(lr=0.02, momentum=0.7),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    def _get_model_checkpoint(self):\n",
    "        return ModelCheckpoint(\n",
    "            self.__model_route,\n",
    "            monitor='val_acc',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='auto',\n",
    "            period=1\n",
    "        )\n",
    "    \n",
    "    def _get_directory_iterator(self, route, is_train: bool = False):\n",
    "      image_generator = image.ImageDataGenerator(rescale=1.0 / 255, horizontal_flip=is_train, \n",
    "                                                 vertical_flip=is_train)\n",
    "        \n",
    "      return image_generator.flow_from_directory(\n",
    "          directory=route,\n",
    "          target_size=(self.__width, self.__height),\n",
    "          batch_size=self.batch_size,\n",
    "          class_mode=\"categorical\")    \n",
    "    \n",
    "    @property\n",
    "    def train_size(self):\n",
    "        return self.__train_size\n",
    "    \n",
    "    @train_size.setter\n",
    "    def train_size(self, train_size):\n",
    "        self.__train_size = train_size\n",
    "        self.train_steps = math.ceil(self.train_size / self.batch_size)\n",
    "    \n",
    "    @property\n",
    "    def validation_size(self):\n",
    "        return self.__validation_size\n",
    "    \n",
    "    @validation_size.setter\n",
    "    def validation_size(self, validation_size):\n",
    "        self.__validation_size = validation_size\n",
    "        self.validation_steps = math.ceil(self.validation_size / self.batch_size)\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self.__batch_size\n",
    "    \n",
    "    @batch_size.setter\n",
    "    def batch_size(self, batch_size):\n",
    "        self.__batch_size = batch_size\n",
    "        self.train_steps = math.ceil(self.train_size / self.batch_size)\n",
    "        self.validation_steps = math.ceil(self.validation_size / self.batch_size)\n",
    "        \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.__model\n",
    "      \n",
    "    @model.setter\n",
    "    def model(self, model):\n",
    "        self.__model = model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## VGG19 fine tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vgg = ImageModel(base_route=\"tiny-imagenet-200\",\n",
    "                 epochs=20, \n",
    "                 train_folder=\"train\",\n",
    "                 validation_folder=\"val/images\", \n",
    "                 fine_tune=True, \n",
    "                 fine_tune_epochs = 3,\n",
    "                 model_name = \"vgg19\", \n",
    "                 model_route = \"vgg19_2.h5\")\n",
    "vgg.build()\n",
    "vgg.model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vgg.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vgg_model = vgg.model\n",
    "vgg_model.save(\"models/vgg19_ft_v2.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cp 'models/vgg19_ft_v2.h5' 'drive/My Drive/Colab Notebooks/TFM-image-feature-selection/models/fine_tuned/vgg19_ft_v2.h5'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet50 fine tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet = ImageModel(base_route=\"tiny-imagenet-200\", \n",
    "                    epochs=10, \n",
    "                    train_folder=\"train\", \n",
    "                    validation_folder=\"val/images\",\n",
    "                    fine_tune=True, fine_tune_epochs = 2, \n",
    "                    model_name = \"resnet\",\n",
    "                    model_route = \"resnet50_v2.h5\")\n",
    "resnet.build()\n",
    "resnet.model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet_model = resnet.model\n",
    "resnet_model.save(\"models/resnet50_v2.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cp 'models/resnet50_v2.h5' 'drive/My Drive/Colab Notebooks/TFM-image-feature-selection/models/fine_tuned/resnet50_v2.h5'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DenseNet201 fine tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "densenet = ImageModel(base_route=\"tiny-imagenet-200\", \n",
    "                      epochs=10, \n",
    "                      train_folder=\"train\", \n",
    "                      validation_folder=\"val/images\",\n",
    "                      fine_tune=True, fine_tune_epochs = 2, \n",
    "                      model_name = \"DenseNet201\",\n",
    "                      model_route = \"densenet201_v2.h5\")\n",
    "densenet.build()\n",
    "densenet.model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "densenet.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "densenet_model = densenet.model\n",
    "densenet_model.save(\"models/densenet201_v2.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cp 'models/densenet201_v2.h5' 'drive/My Drive/Colab Notebooks/TFM-image-feature-selection/models/fine_tuned/densenet201_v2.h5'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Super ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.python.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.python.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.python.keras.layers import concatenate, GlobalAveragePooling2D, Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "vgg19_model = load_model(\"models/vgg19_v2.h5\")\n",
    "resnet50_model = load_model(\"models/resnet50_v2.h5\")\n",
    "densenet_model = load_model(\"models/densenet201_v2.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vgg19_features = Model(inputs=vgg19_model.input, \n",
    "                       outputs=vgg19_model.get_layer('dropout_3').output,\n",
    "                       name='vgg19_features')\n",
    "\n",
    "\n",
    "resnet50_features = Model(inputs=resnet50_model.input, \n",
    "                          outputs=resnet50_model.get_layer('dropout_9').output, \n",
    "                          name='resnet50_features')\n",
    "\n",
    "densenet_features = Model(inputs=densenet_model.input,\n",
    "                          outputs=densenet_model.get_layer('dropout_11').output,\n",
    "                          name='densenet_features')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "size = 64\n",
    "\n",
    "model_input = Input(shape=(size, size, 3))\n",
    "\n",
    "for layer in vgg19_features.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "for layer in resnet50_features.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "for layer in densenet_features.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "vgg_x = vgg19_features(model_input)\n",
    "resnet_x = resnet50_features(model_input)\n",
    "densenet_x = densenet_features(model_input)\n",
    "\n",
    "x = concatenate([vgg_x, resnet_x, densenet_x])\n",
    "\n",
    "##################\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.6)(x)\n",
    "##################\n",
    "\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "image_generator = image.ImageDataGenerator(rescale=1.0 / 255, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "train_iterator = image_generator.flow_from_directory(\n",
    "    directory=\"tiny-imagenet-200/train\", target_size=(size, size),\n",
    "    batch_size=256, class_mode=\"categorical\")\n",
    "\n",
    "val_iterator = image.ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(\n",
    "    directory=\"tiny-imagenet-200/val/images\", target_size=(size, size),\n",
    "    batch_size=256, class_mode=\"categorical\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "checkpoint = ModelCheckpoint(\"model.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_iterator,\n",
    "    steps_per_epoch=390,\n",
    "    epochs=1,\n",
    "    validation_data=val_iterator,\n",
    "    validation_steps=39,\n",
    "    callbacks=[checkpoint, early_stop])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.005, momentum=0.7), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_iterator,\n",
    "    steps_per_epoch=390,\n",
    "    epochs=10,\n",
    "    validation_data=val_iterator,\n",
    "    validation_steps=39,\n",
    "    callbacks=[checkpoint, early_stop])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"models/ensemble_resnet50_vgg19_densenet201_v2.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cp 'models/ensemble_resnet50_vgg19_densenet201_v2.h5' 'drive/My Drive/Colab Notebooks/TFM-image-feature-selection/models/fine_tuned/ensemble_resnet50_vgg19_densenet201_v2.h5' "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load ensemble model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "ensemble_model = load_model(\"models/ensemble_resnet50_vgg19_densenet201_v2.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ensemble_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_extractor = Model(inputs=ensemble_model.input,\n",
    "                          outputs=ensemble_model.get_layer('concatenate_4').output,\n",
    "                          name='feature_extractor')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "image_generator = image.ImageDataGenerator(rescale=1.0 / 255, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "train_iterator = image_generator.flow_from_directory(\n",
    "    directory=\"tiny-imagenet-200/train\", target_size=(64, 64),\n",
    "    batch_size=256, class_mode=\"categorical\")\n",
    "\n",
    "val_iterator = image.ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(\n",
    "    directory=\"tiny-imagenet-200/val/images\", target_size=(64, 64),\n",
    "    batch_size=256, class_mode=\"categorical\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features = feature_extractor.predict_generator(train_iterator)\n",
    "train_labels = train_iterator.labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def save_features(features, labels, file):\n",
    "  header = [i for i in range(features.shape[-1])]\n",
    "  header.append(-1)\n",
    "\n",
    "  with open(file, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    writer.writerow(header)\n",
    "    for i in range(features.shape[0]):\n",
    "      writer.writerow(np.append(features[i], [labels[i]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_features(train_features, train_labels, 'tiny_imagenet_features_ensemble_v3.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Alternative method: Create & save dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv, sys\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras_applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def extract_image_features(image_path, width = 64, height = 64):\n",
    "  img = image.load_img(image_path, target_size=(width, height))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x, data_format='channels_last')\n",
    "\n",
    "  return feature_extractor.predict(x).flatten()\n",
    "\n",
    "def extract_and_save(file, directory_iterator):\n",
    "  with open(file, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "  \n",
    "    count = 0\n",
    "    for filepath, label in zip(directory_iterator.filepaths, directory_iterator.labels):\n",
    "      image_features = extract_image_features(filepath)\n",
    "      writer.writerow(np.append(image_features, [label]))\n",
    "\n",
    "      count += 1\n",
    "      if count % 1000 == 0:\n",
    "        sys.stdout.write(str((count * 100)/directory_iterator.samples) + \" ... \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extract_and_save('.csv', train_iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}